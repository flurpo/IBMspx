{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz9HzXHp1bIsbQV1bnZeEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flurpo/IBMspx/blob/main/Module4_Spacex_Machine_learning_Prediction_flowchart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9Z27mmrphiM"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
        "import numpy as np\n",
        "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
        "import matplotlib.pyplot as plt\n",
        "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
        "import seaborn as sns\n",
        "# Preprocessing allows us to standarsize our data\n",
        "from sklearn import preprocessing\n",
        "# Allows us to split our data into training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Allows us to test parameters of classification algorithms and find the best one\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Logistic Regression classification algorithm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Support Vector Machine classification algorithm\n",
        "from sklearn.svm import SVC\n",
        "# Decision Tree classification algorithm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# K Nearest Neighbors classification algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n"
      ],
      "metadata": {
        "id": "37onArKSuQ5Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y,y_predict):\n",
        "    \"this function plots the confusion matrix\"\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(y, y_predict)\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix');\n",
        "    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fQlHdHe2uUGu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "URL1 = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\"\n",
        "resp1 = requests.get(URL1)\n",
        "data = pd.read_csv(io.BytesIO(resp1.content))\n",
        "print (data.head())\n",
        "print (data.shape)"
      ],
      "metadata": {
        "id": "z7gm5NMRuX4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL2 = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv'\n",
        "resp2 = requests.get(URL2)\n",
        "X = pd.read_csv(io.BytesIO(resp2.content))\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "dBtus6CV8cc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK 1\n",
        "Y = data['Class'].to_numpy()\n",
        "print (Y.shape)\n"
      ],
      "metadata": {
        "id": "I36l7a9ium2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK2\n",
        "transform = preprocessing.StandardScaler()\n",
        "X = transform.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "km6AieqvuzQ1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK3\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "print ('Train set:', X_train.shape,  Y_train.shape)\n",
        "print ('Test set:', X_test.shape,  Y_test.shape)"
      ],
      "metadata": {
        "id": "oWLklXXou8Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK4  LOGISTIC REGRESSION\n",
        "parameters ={'C':[0.01,0.1,1],\n",
        "             'penalty':['l2'],\n",
        "             'solver':['lbfgs']}\n",
        "\n",
        "parameters ={\"C\":[0.01,0.1,1],'penalty':['l2'], 'solver':['lbfgs']}# l1 lasso l2 ridge\n",
        "logreg=LogisticRegression()\n",
        "\n",
        "logreg_cv = GridSearchCV(logreg, parameters, cv=10)\n",
        "logreg_cv.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "JZ5pvufUvtvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
        "print(\"accuracy :\",logreg_cv.best_score_)"
      ],
      "metadata": {
        "id": "k7qKF1oSv_K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK5\n",
        "test_accuracy = logreg_cv.score(X_test, Y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "yhat=logreg_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "WfP3ILgAwEiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK6 Support Vector Machine\n",
        "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n",
        "              'C': np.logspace(-3, 3, 5),\n",
        "              'gamma':np.logspace(-3, 3, 5)}\n",
        "svm = SVC()\n",
        "\n",
        "svm_cv = GridSearchCV(svm, parameters, cv=10)\n",
        "svm_cv.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "e9sRMuFVyjwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\n",
        "print(\"accuracy :\",svm_cv.best_score_)"
      ],
      "metadata": {
        "id": "R-D0a3Jjy4my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK7\n",
        "test_accuracy = svm_cv.score(X_test, Y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "yhat=svm_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "LjqGFiu7y7KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK8 Decision Tree Classifier\n",
        "parameters = {'criterion': ['gini', 'entropy'],\n",
        "     'splitter': ['best', 'random'],\n",
        "     'max_depth': [2*n for n in range(1,10)],\n",
        "     #'max_features': ['auto', 'sqrt'],\n",
        "     'max_features': ['sqrt', 'log2'], #removed 'auto' from 'max_features' in parameters - not a valid option in DecisionTreeClassifier\n",
        "     'min_samples_leaf': [1, 2, 4],\n",
        "     'min_samples_split': [2, 5, 10]}\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "tree_cv = GridSearchCV(tree, parameters, cv=10)\n",
        "tree_cv.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "w_NQ_SkjzE7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",tree_cv.best_params_)\n",
        "print(\"accuracy :\",tree_cv.best_score_)"
      ],
      "metadata": {
        "id": "LeH2j_9WzXPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK9\n",
        "test_accuracy = tree_cv.score(X_test, Y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "yhat = tree_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)\n"
      ],
      "metadata": {
        "id": "e5CG4bBRzRmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK10\n",
        "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "              'p': [1,2]}\n",
        "\n",
        "KNN = KNeighborsClassifier()\n",
        "\n",
        "knn_cv = GridSearchCV(KNN, parameters, cv=10)\n",
        "knn_cv.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "id": "TL0i0p4Ezi8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",knn_cv.best_params_)\n",
        "print(\"accuracy :\",knn_cv.best_score_)"
      ],
      "metadata": {
        "id": "I2X60lLz52lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK11\n",
        "knntest_accuracy = knn_cv.score(X_test, Y_test)\n",
        "print(\"Test Accuracy:\", knntest_accuracy)\n",
        "\n",
        "yhat = knn_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "cvWmxu9j57sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK12\n",
        "print('RESULTS:\\n')\n",
        "print ('Calculated Accuracy Results for Logistic Regression')\n",
        "logreg_accuracy = logreg_cv.score(X_test, Y_test)\n",
        "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
        "print(\"accuracy :\",logreg_cv.best_score_)\n",
        "print(\"Logistic Regression Test Accuracy:\", logreg_accuracy)\n",
        "print('\\n')\n",
        "\n",
        "print ('Calculated Accuracy Results for Support Vector Machine')\n",
        "svm_accuracy = svm_cv.score(X_test, Y_test)\n",
        "print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\n",
        "print(\"accuracy :\",svm_cv.best_score_)\n",
        "print(\"Support Vector Machine Test Accuracy:\", svm_accuracy)\n",
        "print('\\n')\n",
        "\n",
        "print ('Calculated Accuracy Results for Decision Tree')\n",
        "tree_accuracy = tree_cv.score(X_test, Y_test)\n",
        "print(\"tuned hpyerparameters :(best parameters) \",tree_cv.best_params_)\n",
        "print(\"accuracy :\",tree_cv.best_score_)\n",
        "print(\"Decision Tree Test Accuracy:\", tree_accuracy)\n",
        "print(\"removed 'auto' from 'max_features' in parameters - not a valid option in DecisionTreeClassifier\")\n",
        "print('\\n')\n",
        "\n",
        "print ('Calculated Accuracy Results for K-Nearest Neighbors')# Accuracy for K-Nearest Neighbors\n",
        "knn_accuracy = knn_cv.score(X_test, Y_test)\n",
        "print(\"tuned hpyerparameters :(best parameters) \",knn_cv.best_params_)\n",
        "print(\"accuracy :\",knn_cv.best_score_)\n",
        "print(\"K-Nearest Neighbors Test Accuracy:\", knn_accuracy)\n",
        "print('\\n')\n",
        "\n",
        "print('IN SUMMARY:')\n",
        "print('The test data accuracy and confusion matrix response was identical accross the model results. So its very difficult to chose a best model based on the test accuracy.')\n",
        "print('SVM is likely to perform the best overall on this dataset due to its strength in handling high-dimensional data and non-linear relationships. However, Logistic Regression could also be a strong contender if the relationships between the features and the target are mostly linear. KNN should be the worst performer as it is less effective with High-dimensional data. \\n')\n",
        "\n",
        "print('CONCLUSION:')\n",
        "print('The Cross-validataion results (GridSearchCV) should be considered as this is the best performer on the dataset. Based on that weight I would choose the DECISION TREE CLASSIFIER as the best perfromer as it has the highest GridSearchCV result!')\n",
        "print('accuracy : 0.8875')\n",
        "\n",
        "# Find the best performing model\n",
        "#best_accuracy = max(logreg_accuracy, svm_accuracy, tree_accuracy, knn_accuracy)\n",
        "#if best_accuracy == logreg_accuracy:\n",
        "#    print(\"Best Model: Logistic Regression\")\n",
        "#elif best_accuracy == svm_accuracy:\n",
        "#    print(\"Best Model: Support Vector Machine\")\n",
        "#elif best_accuracy == tree_accuracy:\n",
        "#    print(\"Best Model: Decision Tree\")\n",
        "#else:\n",
        "#    print(\"Best Model: K-Nearest Neighbors\")\n",
        "\n",
        "#print(\"Best Accuracy:\", best_accuracy)\n"
      ],
      "metadata": {
        "id": "OoESiY9O6HMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Flowchart Representation\n",
        "css\n",
        "Copy code\n",
        "[Start]\n",
        "    |\n",
        "    v\n",
        "[Load Data]\n",
        "    |\n",
        "    v\n",
        "[Inspect Data Shapes]\n",
        "    |\n",
        "    v\n",
        "[Preprocess Data]\n",
        "    |---> [Standardize Features]\n",
        "    |---> [Extract Target Variable]\n",
        "    |\n",
        "    v\n",
        "[Split Data into Train/Test]\n",
        "    |\n",
        "    v\n",
        "[Choose Classifier]\n",
        "    |------------------------------|\n",
        "    |              |              |\n",
        "    v              v              v\n",
        "[Logistic Regression] [SVM] [Decision Tree] [KNN]\n",
        "    |              |              |              |\n",
        "    v              v              v              v\n",
        "[GridSearchCV for Hyperparameter Tuning]\n",
        "    |\n",
        "    v\n",
        "[Train Classifier]\n",
        "    |\n",
        "    v\n",
        "[Evaluate Classifier]\n",
        "    |---> [Calculate Accuracy]\n",
        "    |---> [Plot Confusion Matrix]\n",
        "    |\n",
        "    v\n",
        "[Store Results]\n",
        "    |\n",
        "    v\n",
        "[Compare Models]\n",
        "    |\n",
        "    v\n",
        "[Visualize Results]\n",
        "    |\n",
        "    v\n",
        "[End]\n",
        "Description of Shapes\n",
        "[Start]: Oval shape to indicate the beginning of the process.\n",
        "[Load Data]: Rectangle representing a process step.\n",
        "[Inspect Data Shapes]: Rectangle for inspection.\n",
        "[Preprocess Data]: Rectangle that branches into standardization and target extraction.\n",
        "[Split Data into Train/Test]: Rectangle indicating data splitting.\n",
        "[Choose Classifier]: Decision shape leading to various classifiers (Logistic Regression, SVM, Decision Tree, KNN).\n",
        "[GridSearchCV for Hyperparameter Tuning]: Rectangle indicating hyperparameter tuning.\n",
        "[Train Classifier]: Rectangle for training the chosen classifier.\n",
        "[Evaluate Classifier]: Rectangle with branches for accuracy calculation and confusion matrix plotting.\n",
        "[Store Results]: Rectangle indicating storage of results.\n",
        "[Compare Models]: Rectangle for comparing the results of different models.\n",
        "[Visualize Results]: Rectangle for final visualization.\n",
        "[End]: Oval shape indicating the end of the process.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "IIrCMQib6VVY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}